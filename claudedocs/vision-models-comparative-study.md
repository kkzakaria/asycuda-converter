# √âtude Comparative: Mod√®les Vision pour Extraction RFCV

**Date**: 2025-10-15
**Contexte**: Remplacement de Mistral OCR pour am√©liorer l'extraction de documents RFCV
**Objectif**: Identifier le mod√®le vision optimal (rapport qualit√©/co√ªt) pour documents douaniers structur√©s

---

## R√©sum√© Ex√©cutif

### üéØ Recommandation Prioritaire

**Pour Production Imm√©diate**: **Qwen2.5-VL-72B** via API (ou self-hosted si budget GPU)

- Performance √©quivalente √† GPT-4o et Claude 3.5 Sonnet
- Sp√©cialis√© en extraction de documents et tableaux
- Co√ªt significativement inf√©rieur (60% moins cher que GPT-4V)
- Open source (Apache 2.0) ‚Üí Option self-hosting disponible

**Alternative Budget/Performance**: **Gemini 2.5 Flash**

- Meilleur rapport co√ªt/performance pour API
- Excellent pour documents structur√©s
- $0.315/M tokens input (10x moins cher que GPT-4V)

---

## 1. Mod√®les Closed-Source (API Payantes)

### 1.1 GPT-4 Vision / GPT-4.1 (OpenAI)

**üéØ Performance**:

- ‚úÖ Pr√©cision OCR: 98.7% (invoices propres), 92.3% (manuscrit)
- ‚úÖ Extraction tableaux: Excellente
- ‚úÖ Documents structur√©s: Tr√®s bonne
- ‚ö†Ô∏è Documents complexes multilingues: Bonne

**üí∞ Tarification** (2025):

- Input: $2.10/M tokens
- Output: $8.40/M tokens
- **Co√ªt estim√© par document RFCV**: ~$0.015-0.025 (1 page, analyse compl√®te)

**üöÄ Disponibilit√©**:

- API officielle OpenAI
- Latence: ~3-5s par document

**üìä Score Global**: 8.5/10

**Avantages**:

- Maturit√© et stabilit√© √©prouv√©es
- Documentation excellente
- Support multilingue robuste

**Inconv√©nients**:

- Co√ªt √©lev√© pour usage intensif
- Vendor lock-in OpenAI
- Pas de self-hosting possible

---

### 1.2 Claude 3.5 Sonnet / Claude 4 Sonnet (Anthropic)

**üéØ Performance**:

- ‚úÖ Pr√©cision OCR: Top-tier (comparable GPT-4V)
- ‚úÖ Extraction tableaux: Excellente
- ‚úÖ Raisonnement complexe: Sup√©rieure
- ‚úÖ Longues s√©quences: Tr√®s bonne (200K context)

**üí∞ Tarification** (2025):

- Input: $3.00/M tokens
- Output: $15.00/M tokens
- **Co√ªt estim√© par document RFCV**: ~$0.020-0.035

**üöÄ Disponibilit√©**:

- API Anthropic
- Latence: ~4-6s par document

**üìä Score Global**: 9/10

**Avantages**:

- Meilleure compr√©hension contextuelle du march√©
- Excellent pour documents complexes/ambigus
- Fen√™tre de contexte large (200K tokens)

**Inconv√©nients**:

- **Co√ªt le plus √©lev√©** de la cat√©gorie
- Pas d'option self-hosting
- Latence l√©g√®rement sup√©rieure

---

### 1.3 Gemini 2.5 Pro / Flash (Google)

#### Gemini 2.5 Pro

**üéØ Performance**:

- ‚úÖ Pr√©cision OCR: Excellente
- ‚úÖ Extraction tableaux: Tr√®s bonne
- ‚úÖ Contexte ultra-long: **1M tokens** (unique!)
- ‚úÖ Multilingue: Sup√©rieure

**üí∞ Tarification** (2025):

- Input: $1.3125/M tokens (<200K context)
- Output: $10.50/M tokens
- Images: $0.005/image
- **Co√ªt estim√© par document RFCV**: ~$0.012-0.020

**üìä Score Global**: 8/10

#### Gemini 2.5 Flash ‚≠ê **MEILLEUR RAPPORT QUALIT√â/PRIX**

**üéØ Performance**:

- ‚úÖ Pr√©cision OCR: Tr√®s bonne (l√©g√®rement < Pro)
- ‚úÖ Extraction tableaux: Bonne
- ‚úÖ Vitesse: **La plus rapide** de la cat√©gorie
- ‚úÖ Documents structur√©s: Excellente

**üí∞ Tarification** (2025):

- Input: $0.315/M tokens
- Output: $2.625/M tokens
- Images: $0.005/image
- **Co√ªt estim√© par document RFCV**: ~$0.003-0.008 ‚ú®

**üöÄ Disponibilit√©**:

- API Google Cloud Vertex AI
- Latence: ~2-3s par document (la plus rapide!)

**üìä Score Global**: 9.5/10 ‚≠ê **RECOMMAND√â API**

**Avantages**:

- **Co√ªt le plus bas** des mod√®les commerciaux
- **Vitesse maximale** (id√©al pour batch processing)
- Bon √©quilibre performance/co√ªt
- Int√©gration Google Cloud (scaling automatique)

**Inconv√©nients**:

- L√©g√®rement moins pr√©cis que GPT-4V/Claude pour cas complexes
- N√©cessite compte Google Cloud

---

### 1.4 Mistral OCR / Pixtral (Mistral AI)

**üéØ Performance**:

- ‚úÖ Pr√©cision OCR: Tr√®s bonne
- ‚ö†Ô∏è Extraction tableaux: Moyenne (**probl√®me actuel RFCV**)
- ‚ö†Ô∏è Documents structur√©s complexes: Besoin d'am√©lioration
- ‚úÖ Vitesse: Bonne

**üí∞ Tarification** (2025):

- OCR: ~$1.00/1000 pages ($1/M tokens √©quivalent)
- Pixtral Large: $2.00/M input, $6.00/M output
- **Co√ªt estim√© par document RFCV**: ~$0.001-0.005 (OCR seul)

**üìä Score Global**: 6.5/10 (pour notre cas d'usage RFCV)

**Avantages**:

- Prix comp√©titif
- Mod√®le fran√ßais (souverainet√© num√©rique)
- Approche hybride OCR + Vision

**Inconv√©nients**:

- **Extraction incompl√®te constat√©e sur RFCV** ‚ùå
- Moins mature que GPT-4V/Claude
- Performances tableaux complexes limit√©es
- **Raison du changement actuel**

---

## 2. Mod√®les Open Source

### 2.1 Qwen2.5-VL (Alibaba Cloud) ‚≠ê **MEILLEUR OPEN SOURCE**

**üéØ Performance**:

#### Qwen2.5-VL-72B

- ‚úÖ Pr√©cision OCR: **√âquivalent GPT-4o** (~75% benchmarks)
- ‚úÖ Extraction tableaux: **Excellente** (sp√©cialis√© documents)
- ‚úÖ Documents structur√©s: **Sup√©rieure** (invoices, manifests)
- ‚úÖ Localisation objets: Tr√®s bonne (bounding boxes JSON)
- ‚úÖ Multilingue: Excellente (incl. handwriting, formules)

#### Qwen2.5-VL-32B

- ‚úÖ Performance: 90% de la version 72B
- ‚úÖ GPU: Moins exigeant (2x moins de VRAM)

#### Qwen2.5-VL-7B

- ‚ö™ Performance: Bonne (70-75% de 72B)
- ‚úÖ GPU: Tr√®s accessible (14.7 GB VRAM)

**üí∞ Co√ªts**:

**Option 1: Self-Hosted**

- Licence: **Gratuit (Apache 2.0)**
- GPU requis:
  - **72B**: 80 GB VRAM (A100) ou 2x A100 40GB
    - Int8 quantization: 40 GB VRAM
    - Int4 quantization: 20 GB VRAM
  - **32B**: 40 GB VRAM (A100)
    - Int4: 16 GB VRAM (T4/RTX 4090)
  - **7B**: 16 GB VRAM (T4/RTX 4080)
    - Int4: 8 GB VRAM (RTX 3080)

- **Co√ªt Cloud GPU** (estimations mensuelles):
  - A100 80GB: $2,500-3,000/mois (AWS/GCP)
  - A100 40GB: $1,200-1,500/mois
  - T4 (7B int4): $300-400/mois

- **Co√ªt par document**: ~$0.0001-0.001 (apr√®s amortissement setup)

**Option 2: API Services** (via providers tiers)

- Disponible sur OpenLM.ai, OpenLaboratory.ai
- Prix: Variable, souvent ~$0.50-1.50/M tokens
- **Co√ªt estim√© par document RFCV**: ~$0.002-0.005

**üöÄ Disponibilit√©**:

- GitHub: <https://github.com/QwenLM/Qwen3-VL>
- HuggingFace: Mod√®les pr√©-entra√Æn√©s disponibles
- Docker containers: Oui
- Frameworks: Transformers, vLLM, SGLang

**üìä Score Global**: 9.5/10 ‚≠ê **RECOMMAND√â OPEN SOURCE**

**Avantages**:

- **Performance comparable GPT-4o √† co√ªt r√©duit**
- **Sp√©cialis√© extraction documents structur√©s** (cas d'usage RFCV)
- Architecture native dynamic-resolution (efficace)
- Support JSON structur√©, bounding boxes
- Multilingue + formules + tables
- **Contr√¥le total** (self-hosting)
- Quantization disponible (r√©duction VRAM)

**Inconv√©nients**:

- N√©cessite expertise DevOps pour self-hosting
- Co√ªt GPU initial √©lev√© (si on-premise)
- Maintenance et mises √† jour √† g√©rer

**üéØ Recommand√© pour**:

- Volume √©lev√© de documents (>10K/mois)
- Budget GPU disponible ou cloud GPU
- Besoin de confidentialit√©/souverainet√© donn√©es
- Cas d'usage sp√©cialis√© documents douaniers

---

### 2.2 LLaVA-1.6 / LLaVA-NeXT

**üéØ Performance**:

- ‚ö™ Pr√©cision OCR: Moyenne √† bonne
- ‚ö†Ô∏è LLaVA 1.5: **Pauvre** sur OCR/documents
- ‚úÖ LLaVA 1.6: **Am√©lioration significative** OCR
- ‚ö™ Extraction tableaux: Moyenne
- ‚úÖ Vision g√©n√©rale: Tr√®s bonne

**üí∞ Co√ªts**:

**Self-Hosted**:

- Licence: **Gratuit (Apache 2.0)**
- GPU requis:
  - **LLaVA-1.5-7B**: 14.7 GB VRAM
  - **LLaVA-1.5-13B**: 27.0 GB VRAM
- Co√ªt cloud GPU: $200-800/mois (selon taille)
- **Co√ªt par document**: ~$0.0001-0.001

**üöÄ Disponibilit√©**:

- HuggingFace: Mod√®les disponibles
- Ollama: Support natif (installation simple)
- Tr√®s facile √† d√©ployer

**üìä Score Global**: 7/10

**Avantages**:

- **Tr√®s cost-efficient** (entra√Ænement 1 jour sur 8xA100)
- **Peu gourmand en ressources** (7B run sur T4)
- Facile √† d√©ployer (Ollama)
- Communaut√© active

**Inconv√©nients**:

- **Performance OCR documents < Qwen** ‚ö†Ô∏è
- Moins sp√©cialis√© extraction structur√©e
- LLaVA 1.5 inadapt√© √† notre cas d'usage
- N√©cessite LLaVA 1.6 minimum

**üéØ Recommand√© pour**:

- Prototypage rapide
- Budget GPU tr√®s limit√©
- Vision g√©n√©raliste (pas sp√©cifique documents)

---

### 2.3 CogVLM / CogAgent (Tsinghua University)

**üéØ Performance**:

- ‚úÖ Pr√©cision OCR: Tr√®s bonne (am√©lior√©e avec CogAgent)
- ‚úÖ Extraction tableaux: Bonne
- ‚úÖ Documents: Bonne (OCR-related tasks enhanced)
- ‚úÖ Zero-shot object detection: Excellente

**üí∞ Co√ªts**:

**Self-Hosted**:

- Licence: **Gratuit (open source)**
- GPU requis (CogVLM 17B):
  - **Full precision**: 80 GB VRAM (A100 80GB)
  - **Int8 quantization**: 32 GB VRAM (A100 40GB, 2xRTX 3090)
  - **Int4 quantization**: 16 GB VRAM (T4, RTX 4090)
- Co√ªt cloud GPU: $300-3,000/mois (selon quantization)
- **Co√ªt par document**: ~$0.0001-0.001

**üöÄ Disponibilit√©**:

- GitHub: Mod√®les disponibles
- Quantization: Int8, Int4 support√©es
- Inference: Peut tourner sur T4 (Int4)

**üìä Score Global**: 7.5/10

**Avantages**:

- Performance qualitative comparable Qwen-VL
- Bonne capacit√© OCR/documents (CogAgent)
- Quantization agressive possible (Int4)
- Detection objets en zero-shot

**Inconv√©nients**:

- GPU requirements √©lev√©s (full model)
- **Moins sp√©cialis√© documents que Qwen2.5-VL**
- Communaut√© plus petite
- Documentation moins compl√®te

**üéØ Recommand√© pour**:

- Besoin zero-shot object detection
- Alternative √† Qwen si GPU limit√© (Int4)
- Cas d'usage mixte (vision + OCR)

---

## 3. Comparaison Synth√©tique

### 3.1 Tableau Comparatif: Performance vs Co√ªt

| Mod√®le | Performance OCR | Extraction Tableaux | Co√ªt/Doc | Latence | D√©ploiement | Score Global |
|--------|----------------|---------------------|----------|---------|-------------|--------------|
| **Qwen2.5-VL-72B** (API) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.002-0.005 | 4-6s | API | ‚≠ê **9.5/10** |
| **Qwen2.5-VL-72B** (Self) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.0001-0.001 | 2-4s | Complex | ‚≠ê **9.5/10** |
| **Gemini 2.5 Flash** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | $0.003-0.008 | 2-3s | Simple | ‚≠ê **9.5/10** |
| Claude 3.5 Sonnet | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.020-0.035 | 4-6s | Simple | 9/10 |
| GPT-4 Vision | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | $0.015-0.025 | 3-5s | Simple | 8.5/10 |
| Gemini 2.5 Pro | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | $0.012-0.020 | 3-5s | Simple | 8/10 |
| CogVLM-17B (Self) | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | $0.0001-0.001 | 3-5s | Moderate | 7.5/10 |
| LLaVA-1.6-13B (Self) | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | $0.0001-0.001 | 2-4s | Simple | 7/10 |
| Mistral OCR | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | $0.001-0.005 | 3-5s | Simple | 6.5/10 |

**L√©gende**:

- ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê: Excellent
- ‚≠ê‚≠ê‚≠ê‚≠ê: Tr√®s bon
- ‚≠ê‚≠ê‚≠ê: Bon
- ‚≠ê‚≠ê: Moyen
- ‚≠ê: Faible

### 3.2 Co√ªt Total Mensuel (estimations pour 10,000 documents RFCV/mois)

| Solution | Co√ªt Mensuel | Break-even vs API |
|----------|--------------|-------------------|
| **Gemini 2.5 Flash** (API) | ~$50-80 | N/A (r√©f√©rence) |
| **Qwen2.5-VL-72B** (API) | ~$20-50 | N/A |
| GPT-4 Vision (API) | ~$150-250 | N/A |
| Claude 3.5 Sonnet (API) | ~$200-350 | N/A |
| Gemini 2.5 Pro (API) | ~$120-200 | N/A |
| **Qwen2.5-VL-72B** (Self, A100 80GB) | ~$3,000 | > 12K docs/mois |
| **Qwen2.5-VL-7B** (Self, T4) | ~$350 | > 7K docs/mois |
| LLaVA-1.6-7B (Self, T4) | ~$300 | > 6K docs/mois |

---

## 4. Analyse Sp√©cifique: Cas d'Usage RFCV

### 4.1 Exigences du Document RFCV

**Complexit√©**:

- ‚úÖ Document structur√© avec sections num√©rot√©es
- ‚úÖ Tableaux multiples (conteneurs, articles)
- ‚úÖ Champs multilingues (fran√ßais + codes internationaux)
- ‚úÖ Donn√©es financi√®res pr√©cises
- ‚úÖ Codes SH au format `XXXX.XX.XX.XX`
- ‚úÖ Dates au format `DD/MM/YYYY`
- ‚ö†Ô∏è Disposition variable selon versions RFCV

**Crit√®res Critiques**:

1. **Extraction tableaux articles** (11+ lignes) - **CRITIQUE**
2. Pr√©cision codes SH (10 digits avec points)
3. Extraction informations exportateur/transport
4. Num√©ro r√©f√©rence document (bas page)
5. Totaux financiers exacts

### 4.2 Mod√®les Adapt√©s au Cas RFCV

#### Tier 1: Excellents ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

1. **Qwen2.5-VL-72B** (API ou Self-hosted)
   - ‚úÖ Sp√©cialis√© documents structur√©s
   - ‚úÖ Extraction tableaux excellente
   - ‚úÖ Output JSON structur√© natif
   - ‚úÖ Bounding boxes pour localisation
   - ‚úÖ Multilingue + formules
   - **Recommand√© #1 pour RFCV**

2. **Gemini 2.5 Flash** (API)
   - ‚úÖ Excellent rapport qualit√©/prix
   - ‚úÖ Rapide (batch processing efficient)
   - ‚úÖ Bonne pr√©cision documents structur√©s
   - ‚ö™ L√©g√®rement moins pr√©cis que Qwen sur tableaux complexes
   - **Recommand√© #2 pour RFCV** (budget API)

#### Tier 2: Tr√®s Bons ‚≠ê‚≠ê‚≠ê‚≠ê

3. **Claude 3.5 Sonnet**
   - ‚úÖ Excellente compr√©hension contextuelle
   - ‚úÖ Gestion ambigu√Øt√©s sup√©rieure
   - ‚ùå Co√ªt prohibitif pour volume √©lev√©
   - **Option si budget n'est pas une contrainte**

4. **GPT-4 Vision**
   - ‚úÖ Maturit√© et stabilit√©
   - ‚úÖ Bonne documentation
   - ‚ö™ Co√ªt mod√©r√©
   - **Alternative stable √† Qwen/Gemini**

#### Tier 3: Acceptables ‚≠ê‚≠ê‚≠ê

5. **Qwen2.5-VL-7B** (Self-hosted)
   - ‚úÖ Bon compromis performance/ressources
   - ‚ö™ Pr√©cision inf√©rieure √† 72B (70-75%)
   - ‚úÖ Accessible GPU (T4)
   - **Option budget GPU limit√©**

6. **CogVLM-17B Int4** (Self-hosted)
   - ‚ö™ Performance correcte
   - ‚úÖ GPU accessible (T4 avec Int4)
   - ‚ö†Ô∏è Moins sp√©cialis√© documents que Qwen
   - **Alternative si Qwen indisponible**

#### Non Recommand√©s ‚ùå

- **Mistral OCR**: Extraction incompl√®te constat√©e (articles vides)
- **LLaVA 1.5**: Performance OCR documents insuffisante
- **LLaVA 1.6**: Performance inf√©rieure √† Qwen pour cas d'usage RFCV

---

## 5. Recommandations Finales

### 5.1 Sc√©nario 1: Production Imm√©diate (API)

**Recommandation**: **Gemini 2.5 Flash** + **Qwen2.5-VL-72B** (via API tierce)

**Strat√©gie**:

1. **D√©marrer avec Gemini 2.5 Flash**:
   - Setup rapide (Google Cloud)
   - Co√ªt minimal ($0.003-0.008/doc)
   - Performance satisfaisante
   - Fallback sur Gemini 2.5 Pro si besoin

2. **Tester en parall√®le Qwen2.5-VL-72B** (via OpenLM.ai ou OpenLaboratory.ai):
   - Performance potentiellement sup√©rieure
   - Co√ªt comparable ($0.002-0.005/doc)
   - √âvaluer sur √©chantillon RFCV r√©els

3. **Impl√©menter routing intelligent**:
   - Documents simples ‚Üí Gemini Flash
   - Documents complexes ‚Üí Qwen2.5-VL ou Gemini Pro

**Co√ªt estim√©**: $50-100/mois (10K documents)

**Impl√©mentation**: 1-3 jours

---

### 5.2 Sc√©nario 2: Volume √âlev√© (Self-Hosted)

**Recommandation**: **Qwen2.5-VL-72B** (Self-hosted avec quantization)

**Strat√©gie**:

1. **Setup initial** (Int8 quantization):
   - Cloud GPU: A100 40GB ($1,200-1,500/mois)
   - Ou on-premise: 2x RTX 4090 (investissement $3,000-4,000)
   - Framework: vLLM pour inference optimis√©e

2. **Optimisations**:
   - Int4 quantization si performance acceptable
   - Batch processing pour maximiser throughput
   - Caching r√©sultats pour documents r√©currents

3. **Break-even**: > 12K documents/mois (vs Gemini Flash API)

**Co√ªt estim√©**: $1,200-1,500/mois (cloud) ou $0.0001/doc apr√®s amortissement

**Impl√©mentation**: 1-2 semaines (setup + optimisation)

---

### 5.3 Sc√©nario 3: Budget Limit√© (Hybrid)

**Recommandation**: **Qwen2.5-VL-7B** (Self-hosted T4) + **Gemini Flash** (fallback)

**Strat√©gie**:

1. **Self-host Qwen2.5-VL-7B** sur T4:
   - Co√ªt cloud T4: $300-400/mois
   - Performance: 70-75% de la version 72B
   - G√®re majorit√© des documents RFCV

2. **Fallback API Gemini Flash**:
   - Documents o√π Qwen2.5-VL-7B √©choue (< 10%)
   - Co√ªt additionnel minimal

**Co√ªt estim√©**: $350-450/mois total

**Impl√©mentation**: 1 semaine

---

## 6. Plan d'Action Recommand√©

### Phase 1: Validation Rapide (Semaine 1)

**Objectif**: Prouver que vision directe r√©sout le probl√®me RFCV

**Actions**:

1. ‚úÖ Impl√©menter appel **Gemini 2.5 Flash** sur 3 PDFs test
2. ‚úÖ Comparer avec r√©sultats actuels Mistral OCR
3. ‚úÖ Mesurer:
   - Taux de r√©ussite validation Zod
   - Erreurs restantes
   - Co√ªt r√©el
   - Latence

**Crit√®res de succ√®s**:

- Taux de r√©ussite > 70% (vs 14.3% actuel)
- Articles extraits correctement
- Co√ªt < $0.01/doc

---

### Phase 2: Production avec API (Semaines 2-3)

**Si Phase 1 r√©ussie**:

1. **Impl√©menter en production** avec Gemini 2.5 Flash
2. **Tester Qwen2.5-VL-72B** (API tierce) en parall√®le
3. **Monitoring**:
   - Taux succ√®s par type de document
   - Co√ªts r√©els
   - Temps de traitement

4. **Optimisations**:
   - Ajuster prompts si n√©cessaire
   - Impl√©menter retry logic
   - Cache r√©sultats

---

### Phase 3: √âvaluation Self-Hosting (Mois 2)

**Si volume justifie**:

1. **Benchmark** Qwen2.5-VL-72B local vs API
2. **Analyse ROI**:
   - Break-even point
   - Co√ªts GPU cloud vs API
   - Latence am√©lioration

3. **D√©cision**: API vs Self-hosted
4. **Migration** si ROI positif

---

## 7. Code d'Impl√©mentation Sugg√©r√©

### Option A: Gemini 2.5 Flash (Recommand√© pour d√©marrage rapide)

```typescript
// lib/config/gemini.config.ts
import { GoogleGenerativeAI } from "@google/generative-ai";

export const geminiClient = new GoogleGenerativeAI(
  process.env.GOOGLE_AI_API_KEY!
);

export const GEMINI_MODEL = "gemini-2.5-flash"; // ou gemini-2.5-pro
```

```typescript
// lib/services/rfcv-vision.service.ts
import { geminiClient, GEMINI_MODEL } from "@/lib/config/gemini.config";
import { rfcvSchema } from "@/lib/schemas/rfcv.schema";
import { normalizeRFCVData } from "@/lib/utils/rfcv-normalizers";

export async function extractRFCVWithVision(
  pdfBuffer: Buffer,
  fileName: string
): Promise<RFCVExtractionResult> {
  const startTime = Date.now();

  try {
    // 1. Convertir PDF en base64
    const base64PDF = pdfBuffer.toString("base64");

    // 2. Pr√©parer le prompt (r√©utiliser buildExtractionPrompt())
    const extractionPrompt = buildExtractionPrompt();

    // 3. Appel √† Gemini Vision directement
    const model = geminiClient.getGenerativeModel({ model: GEMINI_MODEL });

    const result = await model.generateContent([
      extractionPrompt,
      {
        inlineData: {
          mimeType: "application/pdf",
          data: base64PDF,
        },
      },
    ]);

    const content = result.response.text();

    // 4. Parser le JSON
    const extractedData = JSON.parse(content);

    // 5. Normalisation
    const normalizedData = normalizeRFCVData(extractedData);

    // 6. Validation Zod
    const validationResult = rfcvSchema.safeParse(normalizedData);

    if (!validationResult.success) {
      return {
        success: false,
        error: {
          type: "VALIDATION_ERROR",
          message: `Validation √©chou√©e: ${validationResult.error.issues.length} erreur(s)`,
          details: formatZodErrors(validationResult.error),
        },
      };
    }

    return {
      success: true,
      data: validationResult.data,
      metadata: {
        extractionDate: new Date().toISOString(),
        processingTimeMs: Date.now() - startTime,
      },
    };
  } catch (error) {
    // Error handling...
  }
}
```

### Option B: Qwen2.5-VL via API tierce

```typescript
// lib/config/qwen.config.ts
import OpenAI from "openai"; // API compatible OpenAI

export const qwenClient = new OpenAI({
  baseURL: "https://api.openlm.ai/v1", // ou OpenLaboratory.ai
  apiKey: process.env.OPENLM_API_KEY!,
});

export const QWEN_MODEL = "qwen2.5-vl-72b-instruct";
```

```typescript
// lib/services/rfcv-qwen.service.ts
export async function extractRFCVWithQwen(
  pdfBuffer: Buffer,
  fileName: string
): Promise<RFCVExtractionResult> {
  const base64PDF = pdfBuffer.toString("base64");
  const dataUrl = `data:application/pdf;base64,${base64PDF}`;

  const response = await qwenClient.chat.completions.create({
    model: QWEN_MODEL,
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: buildExtractionPrompt() },
          { type: "image_url", image_url: { url: dataUrl } },
        ],
      },
    ],
    response_format: { type: "json_object" },
    temperature: 0,
  });

  const content = response.choices[0].message.content;
  const extractedData = JSON.parse(content);

  // Suite identique (normalisation + validation)
  // ...
}
```

---

## 8. Conclusion

### Synth√®se

**Pour le cas d'usage RFCV**, les mod√®les vision directs offrent une am√©lioration significative par rapport √† l'approche OCR‚ÜíChat actuelle de Mistral:

**Top 3 Recommandations**:

1. **ü•á Gemini 2.5 Flash** (API)
   - Meilleur rapport qualit√©/prix pour d√©marrage
   - Setup simple et rapide
   - Performance satisfaisante pour documents structur√©s

2. **ü•à Qwen2.5-VL-72B** (API ou Self-hosted)
   - Performance maximale (√©quivalent GPT-4o)
   - Sp√©cialis√© extraction documents
   - Option self-hosting pour volume √©lev√©

3. **ü•â Claude 3.5 Sonnet** (API)
   - Si budget n'est pas contrainte
   - Meilleure compr√©hension contextuelle
   - Robustesse maximale

### Prochaines √âtapes Imm√©diates

1. ‚úÖ **Impl√©menter Gemini 2.5 Flash** en priorit√©
2. ‚úÖ **Tester sur les 7 PDFs RFCV** existants
3. ‚úÖ **Mesurer am√©lioration** vs Mistral OCR actuel
4. ‚è≥ **D√©cider** API permanente vs self-hosting
5. ‚è≥ **D√©ployer** en production

**Gain attendu**: Taux de succ√®s **14.3% ‚Üí ‚â•70%** avec co√ªt **< $0.01/document**.

---

**Rapport r√©dig√©**: 2025-10-15
**Sources**: Web search results 2025, documentation officielle des mod√®les, benchmarks publics
